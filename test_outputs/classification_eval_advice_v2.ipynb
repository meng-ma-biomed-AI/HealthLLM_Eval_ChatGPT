{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.read_csv('/home/shan/Desktop/HealthLLM_Eval/test_outputs/health_1cot/health_advice_struc_c2_v2_tb.csv')\n",
    "b = pd.read_csv('/home/shan/Desktop/HealthLLM_Eval/test_outputs/health_1cot/health_advice_struc_c2_v2_tb1.csv')\n",
    "# c = pd.read_csv('/home/shan/Desktop/HealthLLM_Eval/test_outputs/health_0shot/health_struc_0shot_gpt4_2.csv')\n",
    "# d = pd.read_csv('/home/shan/Desktop/HealthLLM_Eval/test_outputs/health_0shot/health_struc_0shot_gpt4_3.csv')\n",
    "# e = pd.read_csv('/home/shan/Desktop/HealthLLM_Eval/test_outputs/health_0shot/health_struc_0shot_gpt4_4.csv')\n",
    "\n",
    "z = pd.concat([a,b]) #concatenate two dataframes\n",
    "# z.to_csv('/home/shan/Desktop/HealthLLM_Eval/test_outputs/health_0shot/health_struc_0shot_gpt4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = '/home/shan/Desktop/HealthLLM_Eval/test_outputs/health_1shot/health_advice_struc_c2_v2_tb.csv'\n",
    "# PATH = '/home/shan/Desktop/HealthLLM_Eval/test_outputs/gpt4_3cot/health_diss_yy_3cot_gpt4.csv'\n",
    "PATH = '/home/shan/Desktop/HealthLLM_Eval/test_outputs/health_3cot/health_diss_yy_3cot.csv'\n",
    "# PATH = '/home/shan/Desktop/HealthLLM_Eval/test_outputs/pubmed_1cot/pudmed_c3_v1_tb.csv'\n",
    "PATH = '/home/shan/Desktop/HealthLLM_Eval/test_outputs/pubmed_0shot/pubmed_0shot_gpt4.csv'\n",
    "df = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer_list'] = 100\n",
    "\n",
    "df = df.rename(columns={\"output\": \"direct_output\"})\n",
    "#df.direct_output.values\n",
    "\n",
    "#pd.set_option('display.max_colwidth', None)\n",
    "direct_output = copy.deepcopy(df.direct_output)\n",
    "# setting all answers to be 100 for easier check later\n",
    "df = pd.DataFrame({'direct_output': direct_output, 'answer_list': [100 for i in range(len(df.context))], 'context_list': df.context, 'y_true': df.label, 'fold': df.fold})\n",
    "answer_list = df.direct_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extract for health advice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "answer_list = [str(i).lower() for i in answer_list]\n",
    "for index, i in enumerate(answer_list):\n",
    "\n",
    "    if 'no health advice' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif '0) no advice' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif '1) weak advice.' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif 'weak' in i:\n",
    "        answer_list[index] = '1' \n",
    "    elif 'strong' in i:\n",
    "        answer_list[index] = '2'\n",
    "    elif 'strong health advice' in i:\n",
    "        answer_list[index] = '2' \n",
    "    elif 'no relationship' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif 'conditionally causative' in i:\n",
    "        answer_list[index] = '2'\n",
    "    elif 'causative relationship' in i:\n",
    "        answer_list[index] ='3'\n",
    "    elif 'directly correlative' in i:\n",
    "        answer_list[index] = '1'\n",
    "    elif 'no advice' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif 'not advice' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif 'weak advice' in i:\n",
    "        answer_list[index] = '1'\n",
    "    elif 'strong advice' in i:\n",
    "        answer_list[index] = '2'\n",
    "    elif 'no' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif 'none' in i:\n",
    "        answer_list[index] = '0'\n",
    "\n",
    "def extract_answer(answer_list):\n",
    "    return [int(re.findall(r'\\d', i)[0]) for i in answer_list]\n",
    "answer_list = extract_answer(answer_list)\n",
    "df['answer_list'] = answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df.answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direct_output</th>\n",
       "      <th>answer_list</th>\n",
       "      <th>context_list</th>\n",
       "      <th>y_true</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no medical advice</td>\n",
       "      <td>0</td>\n",
       "      <td>Our data do not indicate a consistent effect o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weak medical advice</td>\n",
       "      <td>1</td>\n",
       "      <td>Under careful monitoring, chemotherapy dosage ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no medical advice</td>\n",
       "      <td>0</td>\n",
       "      <td>Cancer 2017;123:1989-1997.√Ç¬© 2017 American C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no medical advice</td>\n",
       "      <td>0</td>\n",
       "      <td>The question-behavior effect can be used to re...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>weak medical advice</td>\n",
       "      <td>1</td>\n",
       "      <td>Music training program helps appreciation of m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4779</th>\n",
       "      <td>no medical advice</td>\n",
       "      <td>0</td>\n",
       "      <td>A higher weight gain contributed in a negative...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4780</th>\n",
       "      <td>no medical advice</td>\n",
       "      <td>0</td>\n",
       "      <td>Hypertension prevalence increased with age and...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4781</th>\n",
       "      <td>strong medical advice</td>\n",
       "      <td>2</td>\n",
       "      <td>Continuous monitoring of artemisinin effective...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4782</th>\n",
       "      <td>no medical advice</td>\n",
       "      <td>0</td>\n",
       "      <td>Our findings suggest that tension and post-sur...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4783</th>\n",
       "      <td>strong medical advice</td>\n",
       "      <td>2</td>\n",
       "      <td>Based on the findings of our study as well as ...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4784 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              direct_output  answer_list  \\\n",
       "0         no medical advice            0   \n",
       "1       weak medical advice            1   \n",
       "2         no medical advice            0   \n",
       "3         no medical advice            0   \n",
       "4       weak medical advice            1   \n",
       "...                     ...          ...   \n",
       "4779      no medical advice            0   \n",
       "4780      no medical advice            0   \n",
       "4781  strong medical advice            2   \n",
       "4782      no medical advice            0   \n",
       "4783  strong medical advice            2   \n",
       "\n",
       "                                           context_list  y_true  fold  \n",
       "0     Our data do not indicate a consistent effect o...       0     0  \n",
       "1     Under careful monitoring, chemotherapy dosage ...       1     0  \n",
       "2     Cancer 2017;123:1989-1997.√Ç¬© 2017 American C...       0     0  \n",
       "3     The question-behavior effect can be used to re...       1     0  \n",
       "4     Music training program helps appreciation of m...       1     0  \n",
       "...                                                 ...     ...   ...  \n",
       "4779  A higher weight gain contributed in a negative...       0     3  \n",
       "4780  Hypertension prevalence increased with age and...       0     3  \n",
       "4781  Continuous monitoring of artemisinin effective...       2     3  \n",
       "4782  Our findings suggest that tension and post-sur...       0     3  \n",
       "4783  Based on the findings of our study as well as ...       2     3  \n",
       "\n",
       "[4784 rows x 5 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df.answer_list\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create dictionaries to store the classification report results\n",
    "dictionary1 = {}\n",
    "dictionary2 = {}\n",
    "dictionary3 = {}\n",
    "dictionary4 = {}\n",
    "\n",
    "# Separate the original DataFrame into four separate DataFrames based on the 'fold' column\n",
    "df_fold0 = df[df['fold'] == 0]\n",
    "df_fold1 = df[df['fold'] == 1]\n",
    "df_fold2 = df[df['fold'] == 2]\n",
    "df_fold3 = df[df['fold'] == 3]\n",
    "\n",
    "# Define the y_true column name and the answer_list column name\n",
    "y_true_col = 'y_true'\n",
    "answer_list_col = 'answer_list'\n",
    "\n",
    "# Loop through each of the four DataFrames, run the classification report, and store the results in the appropriate dictionary\n",
    "for i, df_fold in enumerate([df_fold0, df_fold1, df_fold2, df_fold3]):\n",
    "    # Get the fold number\n",
    "    fold_num = i+1\n",
    "    \n",
    "    # Get the y_true and answer_list columns from the DataFrame\n",
    "    y_true = df_fold[y_true_col]\n",
    "    answer_list = df_fold[answer_list_col]\n",
    "    \n",
    "    # Run the classification report and store the results in the appropriate dictionary\n",
    "    classification_results = classification_report(y_true, answer_list, output_dict=True, zero_division=1)\n",
    "    if fold_num == 1:\n",
    "        dictionary1 = classification_results\n",
    "    elif fold_num == 2:\n",
    "        dictionary2 = classification_results\n",
    "    elif fold_num == 3:\n",
    "        dictionary3 = classification_results\n",
    "    elif fold_num == 4:\n",
    "        dictionary4 = classification_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Eval results for /home/shan/Desktop/HealthLLM_Eval/test_outputs/health_0shot/health_struc_0shot_gpt4.csv ================\n",
      "Precision avg: 0.6970132435549095\n",
      "Recall avg: 0.5223192076787182\n",
      "Macro-F1 avg: 0.516880452319237\n",
      "Acc avg: 0.6344063545150501\n"
     ]
    }
   ],
   "source": [
    "# Initialize the accumulators\n",
    "macro_precision_total = 0\n",
    "macro_recall_total = 0\n",
    "macro_f1_total = 0\n",
    "accuracy_total = 0\n",
    "\n",
    "macro_precision_total += dictionary1['macro avg']['precision'] + dictionary2['macro avg']['precision'] + dictionary3['macro avg']['precision'] + dictionary4['macro avg']['precision']\n",
    "macro_recall_total += dictionary1['macro avg']['recall'] + dictionary2['macro avg']['recall'] + dictionary3['macro avg']['recall'] + dictionary4['macro avg']['recall']\n",
    "macro_f1_total += dictionary1['macro avg']['f1-score'] + dictionary2['macro avg']['f1-score'] + dictionary3['macro avg']['f1-score'] + dictionary4['macro avg']['f1-score']\n",
    "accuracy_total += dictionary1['accuracy'] + dictionary2['accuracy'] + dictionary3['accuracy'] + dictionary4['accuracy']\n",
    "\n",
    "macro_precision = macro_precision_total / 4\n",
    "macro_recall = macro_recall_total / 4\n",
    "macro_f1 = macro_f1_total / 4\n",
    "accuracy_avg = accuracy_total / 4\n",
    "\n",
    "# Print the results\n",
    "print(f'=============== Eval results for {PATH} ================')\n",
    "print(f\"Precision avg: {macro_precision}\")\n",
    "print(f\"Recall avg: {macro_recall}\")\n",
    "print(f\"Macro-F1 avg: {macro_f1}\")\n",
    "print(f\"Acc avg: {accuracy_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extraction for causal language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_list = [str(i).lower() for i in answer_list]\n",
    "for index, i in enumerate(answer_list):\n",
    "    if '0) none' in i:\n",
    "        answer_list[index] = '0' \n",
    "    elif '1) correlational' in i:\n",
    "        answer_list[index] = '1' \n",
    "    elif '2) conditional causal' in i:\n",
    "        answer_list[index] = '2'\n",
    "    elif '3) direct causal' in i:\n",
    "        answer_list[index] = '3'   \n",
    "    elif 'no claim' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif 'no relation' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif '- direct causation' in i:\n",
    "        answer_list[index] = '3'\n",
    "    elif '- correlation' in i:\n",
    "        answer_list[index] = '1' \n",
    "    elif 'conditional causation' in i:\n",
    "        answer_list[index] = '2'\n",
    "    elif 'conditionally causative' in i:\n",
    "        answer_list[index] = '2'\n",
    "    elif 'causation' in i:\n",
    "        answer_list[index] = '3'\n",
    "    elif 'causative relationship' in i:\n",
    "        answer_list[index] ='3'\n",
    "    elif '2 - comparison' in i:\n",
    "        answer_list[index] = '1'\n",
    "    elif 'directly correlative' in i:\n",
    "        answer_list[index] = '1'\n",
    "    elif 'no advice' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif 'not advice' in i:\n",
    "        answer_list[index] = '0'\n",
    "    elif 'weak advice' in i:\n",
    "        answer_list[index] = '1'\n",
    "    elif 'strong advice' in i:\n",
    "        answer_list[index] = '2'\n",
    "    elif 'none' in i:\n",
    "        answer_list[index] = '0'\n",
    "    else:\n",
    "        answer_list[index] = '0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_answer(answer_list):\n",
    "    return [int(re.findall(r'\\d', i)[0]) for i in answer_list]\n",
    "answer_list = extract_answer(answer_list)\n",
    "df['answer_list'] = answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>direct_output</th>\n",
       "      <th>answer_list</th>\n",
       "      <th>context_list</th>\n",
       "      <th>y_true</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 - conditional causation</td>\n",
       "      <td>2</td>\n",
       "      <td>A McMahon score of at least 6 calculated on ad...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0 - no relationship</td>\n",
       "      <td>0</td>\n",
       "      <td>The rs7903146 (C/T) polymorphism of the TCF7L2...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 - correlation</td>\n",
       "      <td>1</td>\n",
       "      <td>A fifth of patients with a negative CDS of the...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 - correlation</td>\n",
       "      <td>1</td>\n",
       "      <td>We observed an association between EH/EC and a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1 - correlation</td>\n",
       "      <td>1</td>\n",
       "      <td>The CHA2DS2-VASc tool predicts thromboembolic ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               direct_output  answer_list  \\\n",
       "0  2 - conditional causation            2   \n",
       "1        0 - no relationship            0   \n",
       "2            1 - correlation            1   \n",
       "3            1 - correlation            1   \n",
       "4            1 - correlation            1   \n",
       "\n",
       "                                        context_list  y_true  fold  \n",
       "0  A McMahon score of at least 6 calculated on ad...       0     0  \n",
       "1  The rs7903146 (C/T) polymorphism of the TCF7L2...       1     0  \n",
       "2  A fifth of patients with a negative CDS of the...       1     0  \n",
       "3  We observed an association between EH/EC and a...       1     0  \n",
       "4  The CHA2DS2-VASc tool predicts thromboembolic ...       1     0  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "dff_error_check = df[df['answer_list']== 100]\n",
    "#dff_error_check.display\n",
    "\n",
    "# set the maximum number of rows to display\n",
    "pd.set_option('display.max_rows', len(df))\n",
    "\n",
    "# display the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create dictionaries to store the classification report results\n",
    "dictionary1 = {}\n",
    "dictionary2 = {}\n",
    "dictionary3 = {}\n",
    "dictionary4 = {}\n",
    "\n",
    "# Separate the original DataFrame into four separate DataFrames based on the 'fold' column\n",
    "df_fold0 = df[df['fold'] == 0]\n",
    "df_fold1 = df[df['fold'] == 1]\n",
    "df_fold2 = df[df['fold'] == 2]\n",
    "df_fold3 = df[df['fold'] == 3]\n",
    "\n",
    "# Define the y_true column name and the answer_list column name\n",
    "y_true_col = 'y_true'\n",
    "answer_list_col = 'answer_list'\n",
    "\n",
    "# Loop through each of the four DataFrames, run the classification report, and store the results in the appropriate dictionary\n",
    "for i, df_fold in enumerate([df_fold0, df_fold1, df_fold2, df_fold3]):\n",
    "    # Get the fold number\n",
    "    fold_num = i+1\n",
    "    \n",
    "    # Get the y_true and answer_list columns from the DataFrame\n",
    "    y_true = df_fold[y_true_col]\n",
    "    answer_list = df_fold[answer_list_col]\n",
    "    \n",
    "    # Run the classification report and store the results in the appropriate dictionary\n",
    "    classification_results = classification_report(y_true, answer_list, output_dict=True)\n",
    "    if fold_num == 1:\n",
    "        dictionary1 = classification_results\n",
    "    elif fold_num == 2:\n",
    "        dictionary2 = classification_results\n",
    "    elif fold_num == 3:\n",
    "        dictionary3 = classification_results\n",
    "    elif fold_num == 4:\n",
    "        dictionary4 = classification_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== Eval results for /home/shan/Desktop/HealthLLM_Eval/test_outputs/pubmed_0shot/pubmed_0shot_gpt4.csv ================\n",
      "Precision avg: 0.3458183674859787\n",
      "Recall avg: 0.3928914041417187\n",
      "Macro-F1 avg: 0.30391969281652226\n",
      "Acc avg: 0.36630390017436326\n"
     ]
    }
   ],
   "source": [
    "# Initialize the accumulators\n",
    "macro_precision_total = 0\n",
    "macro_recall_total = 0\n",
    "macro_f1_total = 0\n",
    "accuracy_total = 0\n",
    "\n",
    "macro_precision_total += dictionary1['macro avg']['precision'] + dictionary2['macro avg']['precision'] + dictionary3['macro avg']['precision'] + dictionary4['macro avg']['precision']\n",
    "macro_recall_total += dictionary1['macro avg']['recall'] + dictionary2['macro avg']['recall'] + dictionary3['macro avg']['recall'] + dictionary4['macro avg']['recall']\n",
    "macro_f1_total += dictionary1['macro avg']['f1-score'] + dictionary2['macro avg']['f1-score'] + dictionary3['macro avg']['f1-score'] + dictionary4['macro avg']['f1-score']\n",
    "accuracy_total += dictionary1['accuracy'] + dictionary2['accuracy'] + dictionary3['accuracy'] + dictionary4['accuracy']\n",
    "\n",
    "macro_precision = macro_precision_total / 4\n",
    "macro_recall = macro_recall_total / 4\n",
    "macro_f1 = macro_f1_total / 4\n",
    "accuracy_avg = accuracy_total / 4\n",
    "\n",
    "# Print the results\n",
    "print(f'=============== Eval results for {PATH} ================')\n",
    "print(f\"Precision avg: {macro_precision}\")\n",
    "print(f\"Recall avg: {macro_recall}\")\n",
    "print(f\"Macro-F1 avg: {macro_f1}\")\n",
    "print(f\"Acc avg: {accuracy_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "P = '/home/shan/Desktop/HealthLLM_Eval/data/'\n",
    "\n",
    "health_advice_diss = pd.read_csv(P+'advice_discussion_annotation.csv')\n",
    "health_advice_un = pd.read_csv(P+'advice_unstructured_abs_annotation.csv')\n",
    "health_advice = pd.read_csv(P+'advice_structured_abs_annotation.csv')\n",
    "# press_release = pd.read_csv('press_release_causal_language_annotation.csv')\n",
    "pubmed_causal = pd.read_csv(P+'pubmed_causal_language_annotation.csv')\n",
    "health_advice_diss['type'] = ['diss' for i in health_advice_diss.label]\n",
    "health_advice_un['type'] = ['un' for i in health_advice_un.label]\n",
    "health_advice['type'] = ['struc' for i in health_advice.label]\n",
    "health = pd.concat([health_advice_diss, health_advice_un, health_advice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    health.sentence, health.label, test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = df.context_list, df.answer_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=7e-7, random_state=42,\n",
    "                          max_iter=50000, tol=None)),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.95      2837\n",
      "           1       0.30      0.27      0.29       153\n",
      "           2       0.60      0.34      0.44       155\n",
      "\n",
      "    accuracy                           0.90      3145\n",
      "   macro avg       0.61      0.53      0.56      3145\n",
      "weighted avg       0.89      0.90      0.89      3145\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(X_test)\n",
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "P = '/home/shan/Desktop/HealthLLM_Eval/data/'\n",
    "\n",
    "health_advice_diss = pd.read_csv(P+'advice_discussion_annotation.csv')\n",
    "health_advice_un = pd.read_csv(P+'advice_unstructured_abs_annotation.csv')\n",
    "health_advice = pd.read_csv(P+'advice_structured_abs_annotation.csv')\n",
    "# press_release = pd.read_csv('press_release_causal_language_annotation.csv')\n",
    "pubmed_causal = pd.read_csv(P+'pubmed_causal_language_annotation.csv')\n",
    "health_advice_diss['type'] = ['diss' for i in health_advice_diss.label]\n",
    "health_advice_un['type'] = ['un' for i in health_advice_un.label]\n",
    "health_advice['type'] = ['struc' for i in health_advice.label]\n",
    "health = pd.concat([health_advice_diss, health_advice_un, health_advice]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH = P+'test_data_4folds/health_advice_discuss_annotation_test_folds.csv'\n",
    "# PATH = P+'test_data_4folds/health_advice_unsturctured_abs_annotation_test_folds.csv' \n",
    "# PATH = P+'test_data_4folds/health_advice_sturctured_abs_annotation_test_folds.csv'\n",
    "PATH = P+'test_data_4folds/pubmed_causal_annotation_test_folds.csv'\n",
    "\n",
    "SIZE = 0.2\n",
    "train_df = pubmed_causal\n",
    "# train_df = health \n",
    "train_df = train_df.sample(frac=SIZE).reset_index(drop=True)\n",
    "val_df = pd.read_csv(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9435"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "747+3145+759+4784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1273</td>\n",
       "      <td>0</td>\n",
       "      <td>A McMahon score of at least 6 calculated on ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2734</td>\n",
       "      <td>1</td>\n",
       "      <td>The rs7903146 (C/T) polymorphism of the TCF7L2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2275</td>\n",
       "      <td>1</td>\n",
       "      <td>A fifth of patients with a negative CDS of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2717</td>\n",
       "      <td>1</td>\n",
       "      <td>We observed an association between EH/EC and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2109</td>\n",
       "      <td>1</td>\n",
       "      <td>The CHA2DS2-VASc tool predicts thromboembolic ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>Current chemoprevention guidelines may be fall...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>1958</td>\n",
       "      <td>2</td>\n",
       "      <td>Subsequently, the aggregate may have had a syn...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>1556</td>\n",
       "      <td>3</td>\n",
       "      <td>Overnight closed-loop therapy resulted in bett...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>1023</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The minimum prevalence of HNF1A-MODY among di...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>Concerning patient symptoms, we did not find a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2446 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id  label                                           sentence  \\\n",
       "0            1273      0  A McMahon score of at least 6 calculated on ad...   \n",
       "1            2734      1  The rs7903146 (C/T) polymorphism of the TCF7L2...   \n",
       "2            2275      1  A fifth of patients with a negative CDS of the...   \n",
       "3            2717      1  We observed an association between EH/EC and a...   \n",
       "4            2109      1  The CHA2DS2-VASc tool predicts thromboembolic ...   \n",
       "...           ...    ...                                                ...   \n",
       "2441          619      0  Current chemoprevention guidelines may be fall...   \n",
       "2442         1958      2  Subsequently, the aggregate may have had a syn...   \n",
       "2443         1556      3  Overnight closed-loop therapy resulted in bett...   \n",
       "2444         1023      0  \"The minimum prevalence of HNF1A-MODY among di...   \n",
       "2445          280      0  Concerning patient symptoms, we did not find a...   \n",
       "\n",
       "      fold  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "...    ...  \n",
       "2441     3  \n",
       "2442     3  \n",
       "2443     3  \n",
       "2444     3  \n",
       "2445     3  \n",
       "\n",
       "[2446 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "tds = Dataset.from_pandas(train_df)\n",
    "vds = Dataset.from_pandas(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict()\n",
    "\n",
    "dataset['train'] = tds\n",
    "dataset['validation'] = vds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence_id', 'label', 'sentence'],\n",
       "        num_rows: 123\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence_id', 'label', 'sentence', 'fold'],\n",
       "        num_rows: 2446\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dmis-lab/biobert-base-cased-v1.2 were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dmis-lab/biobert-base-cased-v1.2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "100%|██████████| 1/1 [00:00<00:00, 87.70ba/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 33.92ba/s]\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 04:58, Epoch 200/200]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.402547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.402074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.400951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.399405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.397168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.394465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.390953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.386882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.382123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.376541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.370262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.363158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.355504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.346803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.337891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.328345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.318795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.309117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.299777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.290863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.282439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.274419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.266708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.259377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.252117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.237300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.229507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.221315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.212841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.204329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.195603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.186881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.178360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.170191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.161948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.153342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.143924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.134832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.124977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.115243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.106612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.099284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.093156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.088386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.084760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.081367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.078068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.074804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.070861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.066381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.060467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.055320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.049442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.044212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.039091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.032447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.025400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.018772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.013395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.008675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.005090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.001127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.999814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.000627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.003456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.005516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.004718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.003277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.004585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.007117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.001871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.997451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.996019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.993184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.989439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.986747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.986387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.987836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.992315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.995092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.992975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.991544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.996806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.997704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.000023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.002287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.005665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.008166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.010638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.010895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.011132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.012620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.016522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.011842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.004253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.999028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>0.996779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.195200</td>\n",
       "      <td>1.001325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.004758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.002197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.007190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.012996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.017214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.021567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.021549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.016904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.006565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.004121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.004638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.013175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.020292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.027397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.031365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.032955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.031906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.031536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.032457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.035118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.036235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.037401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.037718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.040912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.052308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.069565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.087376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.099086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.105981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.109357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.111765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.109016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.108106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.105566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.106927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.105656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.098183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.106330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.120335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.140649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.150443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.153086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.142195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.128397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.115225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.111594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.117235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.132931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>1.159820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.196287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.228368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.245279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.241505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.228099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.184354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.148806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.133560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.122139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.118347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.117501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.121229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.135222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.155964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.178991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.200704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.220304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.238813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.252949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.266299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.275310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.283204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.289923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.296238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.301286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.305877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.309746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.314004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.318651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.323892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.328447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.333641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.338041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.340692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.342718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.343832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.344948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.345221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.344490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.343444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.343830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.343400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.344177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.346487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.348438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.351621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.355867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.361448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.366440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>1.372082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>1.378029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.48522635608911513, metrics={'train_runtime': 311.2118, 'train_samples_per_second': 79.046, 'train_steps_per_second': 0.643, 'total_flos': 1618162047590400.0, 'train_loss': 0.48522635608911513, 'epoch': 200.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments\n",
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "\n",
    "# Load the Biobert tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\")\n",
    "\n",
    "# Load the Biobert model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"dmis-lab/biobert-base-cased-v1.2\", num_labels=4)\n",
    "# model = torch.compile(model)\n",
    "dataset = dataset.map(lambda x: tokenizer(x['sentence'], padding='max_length', truncation=True, max_length=128), batched=True)\n",
    "\n",
    "# Define the training arguments for the Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=200,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=1024,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    bf16=True,\n",
    "    torch_compile=True, # optimizations\n",
    "    optim=\"adamw_torch_fused\"\n",
    ")\n",
    "\n",
    "# Define the Trainer object and train the model\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['validation'],\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(dataset['validation'])\n",
    "predicted_labels = predictions.predictions.argmax(axis=-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1273</td>\n",
       "      <td>0</td>\n",
       "      <td>A McMahon score of at least 6 calculated on ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2734</td>\n",
       "      <td>1</td>\n",
       "      <td>The rs7903146 (C/T) polymorphism of the TCF7L2...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2275</td>\n",
       "      <td>1</td>\n",
       "      <td>A fifth of patients with a negative CDS of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2717</td>\n",
       "      <td>1</td>\n",
       "      <td>We observed an association between EH/EC and a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2109</td>\n",
       "      <td>1</td>\n",
       "      <td>The CHA2DS2-VASc tool predicts thromboembolic ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>619</td>\n",
       "      <td>0</td>\n",
       "      <td>Current chemoprevention guidelines may be fall...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442</th>\n",
       "      <td>1958</td>\n",
       "      <td>2</td>\n",
       "      <td>Subsequently, the aggregate may have had a syn...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2443</th>\n",
       "      <td>1556</td>\n",
       "      <td>3</td>\n",
       "      <td>Overnight closed-loop therapy resulted in bett...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2444</th>\n",
       "      <td>1023</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The minimum prevalence of HNF1A-MODY among di...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2445</th>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>Concerning patient symptoms, we did not find a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2446 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentence_id  label                                           sentence  \\\n",
       "0            1273      0  A McMahon score of at least 6 calculated on ad...   \n",
       "1            2734      1  The rs7903146 (C/T) polymorphism of the TCF7L2...   \n",
       "2            2275      1  A fifth of patients with a negative CDS of the...   \n",
       "3            2717      1  We observed an association between EH/EC and a...   \n",
       "4            2109      1  The CHA2DS2-VASc tool predicts thromboembolic ...   \n",
       "...           ...    ...                                                ...   \n",
       "2441          619      0  Current chemoprevention guidelines may be fall...   \n",
       "2442         1958      2  Subsequently, the aggregate may have had a syn...   \n",
       "2443         1556      3  Overnight closed-loop therapy resulted in bett...   \n",
       "2444         1023      0  \"The minimum prevalence of HNF1A-MODY among di...   \n",
       "2445          280      0  Concerning patient symptoms, we did not find a...   \n",
       "\n",
       "      fold  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "...    ...  \n",
       "2441     3  \n",
       "2442     3  \n",
       "2443     3  \n",
       "2444     3  \n",
       "2445     3  \n",
       "\n",
       "[2446 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['answer_list'] = predicted_labels\n",
    "d = predicted_labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create dictionaries to store the classification report results\n",
    "dictionary1 = {}\n",
    "dictionary2 = {}\n",
    "dictionary3 = {}\n",
    "dictionary4 = {}\n",
    "\n",
    "# Separate the original DataFrame into four separate DataFrames based on the 'fold' column\n",
    "df_fold0 = df[df['fold'] == 0]\n",
    "df_fold1 = df[df['fold'] == 1]\n",
    "df_fold2 = df[df['fold'] == 2]\n",
    "df_fold3 = df[df['fold'] == 3]\n",
    "\n",
    "# Define the y_true column name and the answer_list column name\n",
    "y_true_col = 'label'\n",
    "answer_list_col = 'answer_list'\n",
    "\n",
    "# Loop through each of the four DataFrames, run the classification report, and store the results in the appropriate dictionary\n",
    "for i, df_fold in enumerate([df_fold0, df_fold1, df_fold2, df_fold3]):\n",
    "    # Get the fold number\n",
    "    fold_num = i+1\n",
    "    \n",
    "    # Get the y_true and answer_list columns from the DataFrame\n",
    "    y_true = df_fold[y_true_col]\n",
    "    answer_list = df_fold[answer_list_col]\n",
    "    \n",
    "    # Run the classification report and store the results in the appropriate dictionary\n",
    "    classification_results = classification_report(y_true, answer_list, output_dict=True, zero_division=1)\n",
    "    if fold_num == 1:\n",
    "        dictionary1 = classification_results\n",
    "    elif fold_num == 2:\n",
    "        dictionary2 = classification_results\n",
    "    elif fold_num == 3:\n",
    "        dictionary3 = classification_results\n",
    "    elif fold_num == 4:\n",
    "        dictionary4 = classification_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== BERT Eval results for /home/shan/Desktop/HealthLLM_Eval/data/test_data_4folds/pubmed_causal_annotation_test_folds.csv using 20.0% data ================\n",
      "Precision avg: 0.7358248640678164\n",
      "Recall avg: 0.569699061949458\n",
      "Macro-F1 avg: 0.5971158446821065\n",
      "Acc avg: 0.7199524245049902\n"
     ]
    }
   ],
   "source": [
    "# Initialize the accumulators\n",
    "macro_precision_total = 0\n",
    "macro_recall_total = 0\n",
    "macro_f1_total = 0\n",
    "accuracy_total = 0\n",
    "\n",
    "macro_precision_total += dictionary1['macro avg']['precision'] + dictionary2['macro avg']['precision'] + dictionary3['macro avg']['precision'] + dictionary4['macro avg']['precision']\n",
    "macro_recall_total += dictionary1['macro avg']['recall'] + dictionary2['macro avg']['recall'] + dictionary3['macro avg']['recall'] + dictionary4['macro avg']['recall']\n",
    "macro_f1_total += dictionary1['macro avg']['f1-score'] + dictionary2['macro avg']['f1-score'] + dictionary3['macro avg']['f1-score'] + dictionary4['macro avg']['f1-score']\n",
    "accuracy_total += dictionary1['accuracy'] + dictionary2['accuracy'] + dictionary3['accuracy'] + dictionary4['accuracy']\n",
    "\n",
    "macro_precision = macro_precision_total / 4\n",
    "macro_recall = macro_recall_total / 4\n",
    "macro_f1 = macro_f1_total / 4\n",
    "accuracy_avg = accuracy_total / 4\n",
    "\n",
    "# Print the results\n",
    "print(f'=============== BERT Eval results for {PATH} using {SIZE*100}% data ================')\n",
    "print(f\"Precision avg: {macro_precision}\")\n",
    "print(f\"Recall avg: {macro_recall}\")\n",
    "print(f\"Macro-F1 avg: {macro_f1}\")\n",
    "print(f\"Acc avg: {accuracy_avg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from scipy import stats\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ 0.648, 0.712, 0.77, 0.682]\n",
    "b = [ 0.671, 0.670, 0.718, 0.649]\n",
    "c = [ 0.602, 0.640, 0.753, 0.675]\n",
    "d = [ 0.800, 0.821, 0.902, 0.851]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = [a, b, c, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_true \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mlabel\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m f1_score(y_true, a, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m), f1_score(y_true, b, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m), f1_score(y_true, c, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m), f1_score(y_true, d, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmacro\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_true' is not defined"
     ]
    }
   ],
   "source": [
    "f1_score(y_true, a, average='macro'), f1_score(y_true, b, average='macro'), f1_score(y_true, c, average='macro'), f1_score(y_true, d, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = f1_score(y_true, models[0], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = f1_score(y_true, models[3], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.94979599, 0.45604396, 0.56055363]),\n",
       " array([0.97639708, 0.65408805, 0.75238095]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04513588414900216 0.018191981710584577\n"
     ]
    }
   ],
   "source": [
    "print(np.var(x1), np.var(x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 4.15030067e-01 4.22831067e-01 6.17279803e-03]\n",
      " [0.00000000e+00 0.00000000e+00 7.96916609e-01 7.56314317e-04]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.06857629e-03]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_ind \n",
    "\n",
    "models = [a, b, c, d]\n",
    "# initialize an empty matrix to store the F1 scores\n",
    "f1_matrix = np.zeros((4,4))\n",
    "\n",
    "# compute F1 scores for all pairs of models\n",
    "for i in range(len(models)):\n",
    "    for j in range(i+1, len(models)):\n",
    "        f1 = models[i]\n",
    "        f2 = models[j]\n",
    "        # f1 = f1_score(y_true, y_pred1, average=None)\n",
    "        # f2 = f1_score(y_true, y_pred2, average=None)\n",
    "        t_statistic, p_value = ttest_ind(f1, f2, equal_var=True)\n",
    "        f1_matrix[i,j] = p_value\n",
    "\n",
    "# print the matrix\n",
    "print(f1_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(a, b), ttest_ind(a, c), ttest_ind(a, d), ttest_ind(b, c), ttest_ind(b, d), ttest_ind(c, d)\n",
    "ttest_rel(a, b), ttest_rel(a, c), ttest_rel(a, d), ttest_rel(b, c), ttest_rel(b, d), ttest_rel(c, d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tango')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d3cfcd8008262304b046d260093ad381cf77de9f5a3eb5bdd9e4c200977b12e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
